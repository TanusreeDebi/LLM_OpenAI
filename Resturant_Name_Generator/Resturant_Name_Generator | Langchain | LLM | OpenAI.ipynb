{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai.llms import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = OpenAI(openai_api_key=\"***\", temperature=0.6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "name=llm.invoke(\"I want to open a resturant for Indian food. Suggest a fency name for this.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\"Spice Palace\"\n"
     ]
    }
   ],
   "source": [
    "print(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I want to open a resturant for Italian food. Suggest a fency name for this.'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "prompt_template_name = PromptTemplate(input_variables=['cuisine'],\n",
    "                                      template=\"I want to open a resturant for {cuisine} food. Suggest a fency name for this.\"\n",
    "                                     )\n",
    "prompt_template_name.format(cuisine='Italian')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'cuisine': 'Mexican', 'text': '\\n\\n\"El Sabroso Cantina\" '}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.chains import LLMChain\n",
    "\n",
    "chain=LLMChain(llm=llm,prompt=prompt_template_name)\n",
    "chain.invoke(\"Mexican\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = OpenAI(openai_api_key=\"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\", temperature=0.6)\n",
    "prompt_template_name = PromptTemplate(input_variables=['cuisine'],\n",
    "                                      template=\"I want to open a resturant for {cuisine} food. Suggest a fency name for this.\"\n",
    "                                     )\n",
    "name_chain=LLMChain(llm=llm,prompt=prompt_template_name)\n",
    "\n",
    "prompt_template_items = PromptTemplate(input_variables=['resturant_name'],\n",
    "                                      template=\"Suggest some menu items for {resturant_name}.Return it as a comma space\"\n",
    "                                     )\n",
    "food_item_chain=LLMChain(llm=llm,prompt=prompt_template_items)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " separated string\n",
      "\n",
      "1. Vegetable Samosas, Chicken Tikka, and Lamb Seekh Kebab\n",
      "2. Butter Chicken, Palak Paneer, and Garlic Naan\n",
      "3. Chana Masala, Dal Makhani, and Vegetable Biryani\n",
      "4. Tandoori Shrimp, Chicken Vindaloo, and Aloo Gobi\n",
      "5. Mango Lassi, Gulab Jamun, and Kheer \n"
     ]
    }
   ],
   "source": [
    "from langchain.chains import SimpleSequentialChain\n",
    "\n",
    "chain=SimpleSequentialChain(chains=[name_chain,food_item_chain])\n",
    "response=chain.run(\"Indian\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = OpenAI(openai_api_key=\"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\", temperature=0.6)\n",
    "prompt_template_name = PromptTemplate(input_variables=['cuisine'],\n",
    "                                      template=\"I want to open a resturant for {cuisine} food. Suggest a fency name for this.\"\n",
    "                                     )\n",
    "name_chain=LLMChain(llm=llm,prompt=prompt_template_name, output_key=\"resturant_name\")\n",
    "\n",
    "prompt_template_items = PromptTemplate(input_variables=['resturant_name'],\n",
    "                                      template=\"Suggest some menu items for {resturant_name}.Return it as a comma space\"\n",
    "                                     )\n",
    "food_item_chain=LLMChain(llm=llm,prompt=prompt_template_items,output_key=\"menu_items\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'cuisine': 'Arabic',\n",
       " 'resturant_name': '\\n\"Saffron Oasis\"',\n",
       " 'menu_items': '\\n\\n1. Saffron Chicken Curry\\n2. Vegetable Biryani\\n3. Lamb Kebabs\\n4. Tandoori Shrimp\\n5. Palak Paneer\\n6. Naan Bread\\n7. Samosas\\n8. Mango Lassi\\n9. Chicken Tikka Masala\\n10. Vegetable Pakoras\\n11. Rogan Josh\\n12. Aloo Gobi\\n13. Gulab Jamun\\n14. Basmati Rice\\n15. Mango Chutney'}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.chains import SequentialChain\n",
    "\n",
    "chain=SequentialChain(\n",
    "    chains=[name_chain,food_item_chain],\n",
    "    input_variables=[\"cuisine\"],\n",
    "    output_variables=[\"resturant_name\",\"menu_items\"]\n",
    "    \n",
    ")\n",
    "chain.invoke({'cuisine':'Arabic'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = OpenAI(openai_api_key=\"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\", temperature=0.6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m I should use Wikipedia to find out Elon Musk's birthday\n",
      "Action: Wikipedia\n",
      "Action Input: Elon Musk\u001b[0m\n",
      "Observation: Wikipedia is not a valid tool, try one of [wikipedia, Calculator].\n",
      "Thought:\u001b[32;1m\u001b[1;3m I should use Wikipedia to find out Elon Musk's birthday\n",
      "Action: Wikipedia\n",
      "Action Input: Elon Musk birthday\u001b[0m\n",
      "Observation: Wikipedia is not a valid tool, try one of [wikipedia, Calculator].\n",
      "Thought:\u001b[32;1m\u001b[1;3m I should use Wikipedia to find out Elon Musk's birthday\n",
      "Action: Wikipedia\n",
      "Action Input: Elon Musk birthday\u001b[0m\n",
      "Observation: Wikipedia is not a valid tool, try one of [wikipedia, Calculator].\n",
      "Thought:\u001b[32;1m\u001b[1;3m I should use Wikipedia to find out Elon Musk's birthday\n",
      "Action: Calculator\n",
      "Action Input: 2024 - 1971\u001b[0m\n",
      "Observation: \u001b[33;1m\u001b[1;3mAnswer: 53\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I should use Calculator to find out Elon Musk's age in 2024\n",
      "Action: Calculator\n",
      "Action Input: 53 + 3\u001b[0m\n",
      "Observation: \u001b[33;1m\u001b[1;3mAnswer: 56\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I now know the final answer\n",
      "Final Answer: Elon Musk will be 56 years old in 2024.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'when was ELon musk born?What is his age right now in 2024?',\n",
       " 'output': 'Elon Musk will be 56 years old in 2024.'}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.agents import AgentType,initialize_agent, load_tools\n",
    "from langchain.llms import OpenAI\n",
    "\n",
    "tools=load_tools([\"wikipedia\",\"llm-math\"],llm=llm)\n",
    "\n",
    "\n",
    "agent=initialize_agent(\n",
    "    tools,\n",
    "    llm,\n",
    "    agent= AgentType.ZERO_SHOT_REACT_DESCRIPTION,\n",
    "    verbose=True\n",
    ")\n",
    "agent.invoke(\"when was ELon musk born?What is his age right now in 2024?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
